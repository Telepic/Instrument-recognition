{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitch提取\n",
    "使用Thickstn估计泛音音级的步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "sys.path.append('./thickstun/lib/') \n",
    "sys.path.insert(0,'lib/')\n",
    "\n",
    "import thickstun.lib.base_model as base_model\n",
    "import tensorflow as tf\n",
    "import os,mmap\n",
    "import librosa\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# WAV数据集位置\n",
    "filePath = \"./musicnet\"\n",
    "\n",
    "# output file\n",
    "outputfile = './resultPitch/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 滤波器\n",
    "def create_filters(d,k):\n",
    "    x = np.linspace(0, 2*np.pi, d, endpoint=False)\n",
    "    wsin = np.empty((1,d,1,k), dtype=np.float32)\n",
    "    wcos = np.empty((1,d,1,k), dtype=np.float32)\n",
    "    start_freq = 50.\n",
    "    end_freq = 6000.\n",
    "    num_cycles = start_freq*d/44100.\n",
    "    scaling_ind = np.log(end_freq/start_freq)/k\n",
    "    window_mask = 1.0-1.0*np.cos(x)\n",
    "    for ind in range(k):\n",
    "        wsin[0,:,0,ind] = window_mask*np.sin(np.exp(ind*scaling_ind)*num_cycles*x)\n",
    "        wcos[0,:,0,ind] = window_mask*np.cos(np.exp(ind*scaling_ind)*num_cycles*x)\n",
    "            \n",
    "    return wsin,wcos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型读取\n",
    "class Spectrograms(base_model.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Spectrograms, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def define_graph(self):\n",
    "        super(Spectrograms, self).define_graph()\n",
    "        \n",
    "        # lvl1 convolutions are shared between regions\n",
    "        self.k = 512                # lvl1 nodes\n",
    "        self.d = 4096               # lvl1 receptive field\n",
    "        \n",
    "        d2_x = 1          # lvl2 input dims_x\n",
    "        d2_y = 128          # lvl2 input dims_y\n",
    "        k2 = 128        # num lvl2 filters\n",
    "        stride_y = 2    # lvl2 stride\n",
    "        \n",
    "        d3_x = 25 # lvl3 input dims_x\n",
    "        d3_y = 1 # lvl3 input dims_y (fully connected)\n",
    "        k3 = 4096 # num lvl3 filters\n",
    "\n",
    "        num_regions  = 1 + (self.window-self.d)/self.stride\n",
    "        #print 'First layer regions: ({},{})'.format(num_regions,self.k)\n",
    "        num_regions2_x  = 1 + (num_regions-d2_x)/1\n",
    "        num_regions2_y = 1 + (self.k-d2_y)/stride_y\n",
    "        #print 'Second layer regions: ({},{})'.format(num_regions2_x,num_regions2_y)\n",
    "        num_regions3_x = 1 + (num_regions2_x - d3_x)/1\n",
    "        num_regions3_y = 1 + (num_regions2_y - d3_y)/1\n",
    "\n",
    "        wsin,wcos = create_filters(self.d,self.k)\n",
    "\n",
    "        print ('---- Weights ----')\n",
    "        wscale = .0001\n",
    "        with tf.compat.v1.variable_scope('parameters'):\n",
    "            w = tf.Variable(wscale*tf.random.normal([d2_x,d2_y,1,k2],seed=999))\n",
    "            print ('w',w)\n",
    "            wavg = self.register_weights(w,'w',average=.9998)\n",
    "            w2 = tf.Variable(wscale*tf.random.normal([d3_x,d3_y,k2,k3],seed=999))\n",
    "            print ('w2',w2)\n",
    "            w2avg = self.register_weights(w2,'w2',average=.9998)\n",
    "            beta = tf.Variable(wscale*tf.random.normal([int(num_regions3_x*num_regions3_y*k3),self.m],seed=999))\n",
    "            print ('beta',beta)\n",
    "            betaavg = self.register_weights(beta,'beta',average=.9998)\n",
    "\n",
    "        print ('---- Layers ----')\n",
    "        with tf.compat.v1.variable_scope('queued_model'):\n",
    "            zx = tf.square(tf.nn.conv2d(self.xq,wsin,strides=[1,1,self.stride,1],padding='VALID')) \\\n",
    "               + tf.square(tf.nn.conv2d(self.xq,wcos,strides=[1,1,self.stride,1],padding='VALID'))\n",
    "            print ('zx',zx)\n",
    "            z2 = tf.nn.relu(tf.nn.conv2d(tf.math.log(zx+10e-15),w,strides=[1,1,1,stride_y],padding='VALID',data_format='NCHW'))\n",
    "            print ('z2',z2)\n",
    "            z3 = tf.nn.relu(tf.nn.conv2d(z2,w2,strides=[1,1,1,1],padding='VALID',data_format='NCHW'))\n",
    "            print ('z3',z3)\n",
    "            y = tf.matmul(tf.reshape(z3,[self.batch_size,int(num_regions3_x*num_regions3_y*k3)]),beta)\n",
    "            print ('y',y)\n",
    "            self.loss = tf.reduce_mean(tf.nn.l2_loss(y-tf.reshape(self.yq,[self.batch_size,self.m])))\n",
    "\n",
    "        with tf.compat.v1.variable_scope('direct_model'):\n",
    "            self.zx = tf.square(tf.nn.conv2d(self.xd,wsin,strides=[1,1,self.stride,1],padding='VALID')) \\\n",
    "                    + tf.square(tf.nn.conv2d(self.xd,wcos,strides=[1,1,self.stride,1],padding='VALID'))\n",
    "            self.z2 = tf.nn.relu(tf.nn.conv2d(tf.math.log(self.zx+10e-15),wavg,strides=[1,1,1,stride_y],padding='VALID',data_format='NCHW'))\n",
    "            self.z3 = tf.nn.relu(tf.nn.conv2d(self.z2,w2avg,strides=[1,1,1,1],padding='VALID',data_format='NCHW'))\n",
    "            self.y_direct = tf.matmul(tf.reshape(self.z3,[tf.shape(self.xd)[0],int(num_regions3_x*num_regions3_y*k3)]),betaavg)\n",
    "            self.loss_direct = tf.reduce_mean(tf.nn.l2_loss(self.y_direct-self.yd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测函数，通过读取路径path的音频文件，将其转化为预测数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(path):\n",
    "    labels = None\n",
    "    try: model.stop()\n",
    "    except NameError: pass\n",
    "    model = Spectrograms(labels,checkpoint_path='./thickstun/convnet_experimental2_morelvl3/', outputs=1, window=16384, mmap=True,\n",
    "                         normalize=True, extended_test_set=False, use_mirex=True, init=False, pitch_transforms=5, jitter=.1,\n",
    "                         restrict=False,isTest=False)\n",
    "    print ('finish model loading...')\n",
    "    for i,f in enumerate(os.listdir('./thickstun/data/records/')[:]):\n",
    "        if (not os.path.isfile(path+f)):\n",
    "            try:\n",
    "                print(f + ' complete!')\n",
    "                mse_test, Yhat, Y, mse_breakdown, avp_breakdown = model.sample_records(int(f[:-4]), 10000, fixed_stride=512)\n",
    "                np.save(path+f,Yhat.T)\n",
    "            except Exception as e: print (e)\n",
    "        else: print ('exist') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Weights ----\n",
      "w <tf.Variable 'parameters/Variable:0' shape=(1, 128, 1, 128) dtype=float32>\n",
      "WARNING:tensorflow:From D:\\Instruments Recoginition\\thickstun\\lib\\base_model.py:118: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "w2 <tf.Variable 'parameters/Variable_2:0' shape=(25, 1, 128, 4096) dtype=float32>\n",
      "beta <tf.Variable 'parameters/Variable_4:0' shape=(790528, 128) dtype=float32>\n",
      "---- Layers ----\n",
      "zx Tensor(\"queued_model/add:0\", shape=(150, 1, 25, 512), dtype=float32)\n",
      "z2 Tensor(\"queued_model/Relu:0\", shape=(150, 128, 25, 193), dtype=float32)\n",
      "z3 Tensor(\"queued_model/Relu_1:0\", shape=(150, 4096, 1, 193), dtype=float32)\n",
      "y Tensor(\"queued_model/MatMul:0\", shape=(150, 128), dtype=float32)\n",
      "finish model loading...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    labels = None\n",
    "    try: model.stop()\n",
    "    except NameError: pass\n",
    "    model = Spectrograms(labels,checkpoint_path='./thickstun/convnet_experimental2_morelvl3/', outputs=1, window=16384, mmap=True,\n",
    "                         normalize=True, extended_test_set=False, use_mirex=True, init=False, pitch_transforms=5, jitter=.1,\n",
    "                         restrict=False)\n",
    "    print ('finish model loading...')\n",
    "    print(name)\n",
    "    data, y = librosa.load('./mp3/'+name, sr=44100)\n",
    "    np.save('./thickstun/tmp/test.npy',data)\n",
    "    fd = open('./thickstun/tmp/test.npy', 'r+b')\n",
    "    buff = mmap.mmap(fd.fileno(), 0, access=mmap.ACCESS_DEFAULT)\n",
    "    mse_test, Yhat, Y, mse_breakdown, avp_breakdown = model.sample_records(buff, 10000, fixed_stride=512)\n",
    "\n",
    "    np.save('./thickstun/pitch/'+name[:-4]+'.npy', Yhat)\n",
    "'''\n",
    "\n",
    "# 将文件目录中的所有音频文件进行预测，将其保存到resultPitch文件夹中\n",
    "labels = None\n",
    "# 先清空可能存在的模型内存（一般不会有）\n",
    "try: model.stop()\n",
    "except NameError: pass\n",
    "# 读取已有模型\n",
    "model = Spectrograms(labels,checkpoint_path='./thickstun/Model_Data/convnet_experimental2_morelvl3/', outputs=1, window=16384, mmap=True,\n",
    "                     normalize=True, extended_test_set=False, use_mirex=True, init=False, pitch_transforms=5, jitter=.1,\n",
    "                     restrict=False)\n",
    "print ('finish model loading...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, y = librosa.load(\"D:/Instruments Recoginition/musicnet/Predict.wav\", sr=44100)\n",
    "mse_test, Yhat, Y, mse_breakdown, avp_breakdown = model.sample_records(data, fixed_stride=512)\n",
    "np.save('Predict_pitch.npy', Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 330/330 [43:11<00:00,  7.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# 计算文件数\n",
    "lin = 0\n",
    "for root, dirs, files in os.walk(filePath):\n",
    "    for file in files:\n",
    "        path = os.path.join(root, file)\n",
    "        if '.wav' in path:\n",
    "            lin += 1\n",
    "            \n",
    "with tqdm(total=lin) as pbar:\n",
    "    for root, dirs, pfiles in os.walk(filePath):\n",
    "        for pfile in pfiles:\n",
    "            path = os.path.join(root, pfile)\n",
    "            if '.wav' in path or '.mp3' in path:\n",
    "                name = pfile.replace(\".wav\", \"\")\n",
    "                name = name.replace(\".mp3\", \"\")\n",
    "                data, y = librosa.load(path, sr=44100)\n",
    "                # 避免加载模型之后导致内存不够，因此采用mmap动态存取数据，不过有些错误，这里不准备使用\n",
    "                '''\n",
    "                np.save('temp.npy', data)\n",
    "                fd = open('temp.npy', 'wb')\n",
    "                buff = mmap.mmap(fd.fileno(), 0, access=mmap.ACCESS_DEFAULT)\n",
    "                '''\n",
    "                # print(pfile)\n",
    "                mse_test, Yhat, Y, mse_breakdown, avp_breakdown = model.sample_records(data, fixed_stride=512)\n",
    "                \n",
    "                np.save(outputfile + name + '.npy', Yhat)\n",
    "                \n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1759.wav\n",
    "8584704 True\n",
    "4149\n",
    "512'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
